{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Introduction to Listening Machines - Audio Signal Processing\n",
    "    1. Concepts\n",
    "        - Samples\n",
    "        - Sample rate\n",
    "        - Duration\n",
    "        - Channels\n",
    "    2. Waveforms\n",
    "    3. FFTs\n",
    "    4. STFT\n",
    "    5. Spectrograms\n",
    "    6. Analyzing stream of audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_filename = 'recording.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recording audio with sounddevice and soundfile\n",
    "# \n",
    "# https://python-soundfile.readthedocs.io/\n",
    "# https://python-sounddevice.readthedocs.io\n",
    "\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# config\n",
    "samplerate = 44100\n",
    "duration = 5\n",
    "channels = 1\n",
    "\n",
    "print(f\"Recording for {duration} seconds at {samplerate} Hz...\")\n",
    "\n",
    "# record audio from the microphone into a numpy array with sounddevice\n",
    "recording = sd.rec(\n",
    "    int(duration * samplerate),\n",
    "    samplerate=samplerate,\n",
    "    channels=channels,\n",
    "    dtype='float32'\n",
    ")\n",
    "sd.wait()\n",
    "\n",
    "print(f\"Recording finished. Saving to {recording_filename}...\")\n",
    "\n",
    "# save the file with soundfile\n",
    "sf.write(\n",
    "    recording_filename,\n",
    "    recording,\n",
    "    samplerate,\n",
    "    subtype='PCM_16'\n",
    "    )\n",
    "\n",
    "print(f\"File '{recording_filename}' saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing audio with sounddevice and soundfile\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "# data is a numpy array!\n",
    "data, samplerate = sf.read(\n",
    "    recording_filename,\n",
    "    dtype='float32'    \n",
    ")\n",
    "\n",
    "print(f\"Playing '{recording_filename}'...\")\n",
    "sd.play(data, samplerate)\n",
    "\n",
    "sd.wait()\n",
    "\n",
    "print(f\"Finished playing '{recording_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the recording with iPython Display Audio\n",
    "from IPython.display import Audio, display\n",
    "Audio(recording_filename) # or Audio(data, rate=sample_rate) from the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at samples in a recording with NumPy and matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "\n",
    "# load in our recording\n",
    "data, sample_rate = sf.read(recording_filename)\n",
    "\n",
    "# get some basic info\n",
    "print(f\"Sample rate: {sample_rate} Hz\")\n",
    "print(f\"Duration: : {len(data) / sample_rate:.2f} seconds\")\n",
    "print(f\"Number of samples: {len(data)}\")\n",
    "print(f\"Shape: {data.shape}\") # (n_samples,) for mono (n samples, n_channels) for stereo\n",
    "\n",
    "# create time axis in seconds\n",
    "duration = len(data) / sample_rate\n",
    "time = np.linspace(0, duration, len(data)) # not sure what linspace is? let's look at the documentation!\n",
    "\n",
    "# plot the waveform\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(time, data) # x, y axis\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Audio WaveForm')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at / accessing individual samples\n",
    "\n",
    "# First 10 samples\n",
    "print(\"First 10 samples: \", data[:10])\n",
    "\n",
    "# Sample at 1 second\n",
    "sample_index = int(1.0 * sample_rate)\n",
    "print(\"Sample at 1 second: \", data[sample_index])\n",
    "\n",
    "# min and max amplitude\n",
    "print(\"Max amplitude: \", np.max(data))\n",
    "print(\"Min amplitude: \", np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Silence seconds 2-3 in the recording and play it back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Reverse the recording and play it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing sound with FFT\n",
    "\n",
    "# Origins of FFT\n",
    "# Discrete Forier transform: https://en.wikipedia.org/wiki/Discrete_Fourier_transform\n",
    "# Gauss: https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss\n",
    "# Fourier: https://en.wikipedia.org/wiki/Joseph_Fourier\n",
    "\n",
    "# Cooley-Tukey FFT Algorithm \n",
    "# Original paper: https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf\n",
    "# Wikipedia: https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "\n",
    "# load in audio\n",
    "data, sample_rate = sf.read(recording_filename)\n",
    "\n",
    "# compute FFT using numpy\n",
    "# FFT converts time-domain signal to frequency-domain\n",
    "fft = np.fft.fft(data)\n",
    "\n",
    "# get magnitude spectrum (absolute values)\n",
    "# this tells us how much energy is at each frequency\n",
    "magnitude = np.abs(fft)\n",
    "\n",
    "# create frequency axis\n",
    "# np.fft.fftfreq gives us the frequency bins for the FFT output\n",
    "freq_bins = np.fft.fftfreq(len(data), 1/sample_rate)\n",
    "\n",
    "# only plot positive frequencies (FFT is symmetric)\n",
    "# Nyquist theorem: we can only represent frequencies up to sample_rate / 2\n",
    "positive_freq_idx = freq_bins >= 0\n",
    "positive_freq = freq_bins[positive_freq_idx]\n",
    "positive_magnitude = magnitude[positive_freq_idx]\n",
    "\n",
    "# plot FFT spectrum\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(positive_freq, positive_magnitude)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.title('FFT Frequency Spectrum (Full Signal)')\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 5000) # Focus on 0-5kHz - most audio content is here - comment this out / play with the values!\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"FFT computed on {len(data)} samples\")\n",
    "print(f\"Frequency resolution: {sample_rate / len(data):.2f} Hz per bin\")\n",
    "print(f\"Max frequency representable: {sample_rate / 2} Hz (Nyquist theorem)\") # how would we affect this?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at Short-Time Fourier Transform (STFT) with librosa\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load in recording with librosa\n",
    "y, sr = librosa.load(recording_filename, sr=None)\n",
    "\n",
    "# compute STFT\n",
    "# STFT breaks down the signal into overlapping windows and computes FFT\n",
    "# This gives us frequency content over time (unlike FFT which is frequency for the whole signal)\n",
    "\n",
    "stft = librosa.stft(y)\n",
    "\n",
    "# stft is a complex-valued matrix\n",
    "# Shape: (n_frequencies, n_time_frames)\n",
    "print(f\"STFT shape: {stft.shape}\")\n",
    "print(f\"Number of frequency bins: {stft.shape[0]}\")\n",
    "print(f\"Number of time frames: {stft.shape[1]}\")\n",
    "\n",
    "# get magnitude (absolute value) of STFT\n",
    "magnitude = np.abs(stft)\n",
    "\n",
    "# convert to decibles for better visualization\n",
    "# this is the poewr spectral density in dB\n",
    "S_db = librosa.power_to_db(magnitude**2, ref=np.max)\n",
    "\n",
    "# plot STFT magnitude over time\n",
    "# we can visualize it as a 2D plot: frequency vs time\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(S_db, aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.xlabel('Time Frame')\n",
    "plt.ylabel('Frequency Bin')\n",
    "plt.title('STFT Magnitude (dB)')\n",
    "plt.colorbar(label='dB')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# get actual frequency and time values\n",
    "frequencies = librosa.fft_frequencies(sr=sr)\n",
    "times = librosa.frames_to_time(np.arange(S_db.shape[1]), sr=sr )\n",
    "\n",
    "print(f\"Frequency range: {frequencies[0]:.1f} Hz to {frequencies[-1]:.1f} Hz\")\n",
    "print(f\"Time range: {times[0]:.2f} s to {times[-1]:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at spectrogram\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load audio\n",
    "y, sr = librosa.load(recording_filename, sr=None)\n",
    "\n",
    "# compute STFT\n",
    "D = librosa.stft(y)\n",
    "\n",
    "# convert to power spectrogram (magnitude squared)\n",
    "S = np.abs(D)**2\n",
    "\n",
    "# Convert to decibels\n",
    "S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "# Visualize spectrogram using librosa's built-in display function\n",
    "# This automatically handles frequency and time axes correctly\n",
    "plt.figure(figsize=(12,6))\n",
    "librosa.display.specshow(\n",
    "    S_db,\n",
    "    x_axis='time',\n",
    "    y_axis='hz',\n",
    "    sr=sr\n",
    "    )\n",
    "plt.colorbar(\n",
    "    format='%+2.0f db', \n",
    "    label='Power (db)'\n",
    "    )\n",
    "plt.title('Spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# above is a linar frequency scale\n",
    "# we can use Mel scale which is more aligneed with our human ear perception of frequency\n",
    "\n",
    "S_mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "S_mel_db = librosa.power_to_db(S_mel, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "librosa.display.specshow(\n",
    "    S_mel_db,\n",
    "    x_axis='time',\n",
    "    y_axis='mel',\n",
    "    sr=sr\n",
    "    )\n",
    "plt.colorbar(\n",
    "    format='%+2.0f db', \n",
    "    label='Power (db)'\n",
    "    )\n",
    "plt.title('Mel Spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real time analysis from microphone\n",
    "# Using sounddevice's callback to process audio as it comes in\n",
    "\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "# config\n",
    "SAMPLE_RATE = 44100\n",
    "BLOCK_SIZE = 2048 # number of samples per block\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"This function is called for each audio block\"\"\"\n",
    "    if status:\n",
    "        print(f\"Status: {status}\")\n",
    "    \n",
    "    # indata is a numpy array of audio samples\n",
    "    # calculate the volume using Root Mean Square (RMS)\n",
    "    volume = np.sqrt(np.mean(indata**2))\n",
    "\n",
    "    # simple volume metter with astrisks\n",
    "    meter = '*' * int(volume * 200)\n",
    "    print(f\"Volume:  {meter}\")\n",
    "\n",
    "print(\"Listening to the microphone...stop this cell to stop\")\n",
    "\n",
    "try:\n",
    "    with sd.InputStream(\n",
    "        samplerate=SAMPLE_RATE,\n",
    "        blocksize=BLOCK_SIZE,\n",
    "        channels=1,\n",
    "        callback=audio_callback\n",
    "    ):\n",
    "        sd.sleep(10000) # listen for 10 seconds\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fundamental pitch detection using FFT\n",
    "# Find the strongest frequency in an audio recording\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load audio data\n",
    "data, sample_rate = sf.read(recording_filename)\n",
    "\n",
    "# if stereo, convert to mono\n",
    "if len(data.shape) > 1:\n",
    "    data = data[:, 0]\n",
    "\n",
    "# take a short segment (e.g. 0.1 seconds) for analysis\n",
    "segment_duration = 0.1 # in seconds\n",
    "segment_samples = int(segment_duration * sample_rate)\n",
    "segment = data[:segment_samples]\n",
    "\n",
    "# compute FFT\n",
    "fft = np.fft.fft(segment)\n",
    "magnitude = np.abs(fft)\n",
    "\n",
    "# get frequency bins\n",
    "freq_bins = np.fft.fftfreq(len(segment), 1/sample_rate)\n",
    "\n",
    "# only look at positive frequencies\n",
    "positive_idx = freq_bins > 0\n",
    "positive_freq = freq_bins[positive_idx]\n",
    "positive_magnitude = magnitude[positive_idx]\n",
    "\n",
    "# find the fundamental frequency (strongest frequency)\n",
    "peak_idx = np.argmax(positive_magnitude)\n",
    "fundamental_freq = positive_freq[peak_idx]\n",
    "\n",
    "print(f\"Fundamental frequency: {fundamental_freq:.1f} Hz\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(positive_freq, positive_magnitude)\n",
    "plt.axvline(x=fundamental_freq, color='r', linestyle='--', label=f'Fundamental: {fundamental_freq:.1f} Hz')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Frequency Spectrum with Fundamental Pitch')\n",
    "plt.xlim(0, 2000) # Focused within speech/music range\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitch detection from speech using librosa\n",
    "# Track how pitch changes over time in a speech recording\n",
    "\n",
    "# load audio\n",
    "y, sr = librosa.load(recording_filename)\n",
    "\n",
    "# use librosa's pyin for pitch detection\n",
    "# pyin is good for speech and monophonic audio\n",
    "# fmin and f max set the range for frequencies to look for\n",
    "\n",
    "f0, voiced_flag, voiced_probs = librosa.pyin(\n",
    "    y,\n",
    "    fmin = 50, # min frequency (Hz) - low male voice\n",
    "    fmax = 500, # maximum frequency (Hz) - high female voice\n",
    "    sr = sr\n",
    ")\n",
    "\n",
    "# f0 contains the detected pitch for each time frame\n",
    "# NaN (not a number) means no pitch deteted (silence or noise)\n",
    "\n",
    "# get time values for each frame\n",
    "times = librosa.times_like(f0, sr=sr)\n",
    "\n",
    "# plot the pitch over time\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(times, f0, label='Detected Pitch')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.title('Pitch (F0) OVer Time in Speech')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# print some states\n",
    "valid_pitches = f0[~np.isnan(f0)] # remove NaN values\n",
    "if len(valid_pitches) > 0:\n",
    "    print(f\"Average pitch: {np.mean(valid_pitches):.1f} Hz\")\n",
    "    print(f\"Pitch range: {np.min(valid_pitches):.1f} - {np.max(valid_pitches):.1f} Hz\")\n",
    "else:\n",
    "    print(\"No pitch detected in recording\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detects a specific pitch from microphone and trigger an action\n",
    "# Prints a message when we detect a pitch near 500hz\n",
    "\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "# config\n",
    "SAMPLE_RATE = 44100\n",
    "BLOCK_SIZE = 4096\n",
    "TARGET_FREQ = 500 # frequency to detect\n",
    "TOLERANCE = 50\n",
    "MIN_VOLUME = 0.01\n",
    "\n",
    "def find_fundamental(audio_data, sample_rate):\n",
    "    \"\"\"Find the fundamental frequency in audio data using FFT\"\"\"\n",
    "\n",
    "    # Compute FFT\n",
    "    fft = np.fft.fft(audio_data)\n",
    "    magnitude = np.abs(fft)\n",
    "\n",
    "    # get frequency bins\n",
    "    freq_bins = np.fft.fftfreq(len(audio_data), 1/sample_rate)\n",
    "\n",
    "    # only look at the positive frequencies betweeen 50-2000 Hz\n",
    "    valid_idx = (freq_bins > 50) & (freq_bins < 2000)\n",
    "\n",
    "    if not np.any(valid_idx):\n",
    "        return 0\n",
    "\n",
    "    valid_freq = freq_bins[valid_idx]\n",
    "    valid_magnitude = magnitude[valid_idx]\n",
    "\n",
    "    # find peak frequency\n",
    "    peak_idx = np.argmax(valid_magnitude)\n",
    "    return valid_freq[peak_idx]\n",
    "\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"Called for each audio block\"\"\"\n",
    "    if status:\n",
    "        print(f'Status: {status}')\n",
    "\n",
    "    # flatten to 1D array\n",
    "    audio = indata[:, 0]\n",
    "\n",
    "    # check if there is enough volume\n",
    "    volume = np.sqrt(np.mean(audio**2))\n",
    "    if volume < MIN_VOLUME:\n",
    "        return\n",
    "\n",
    "    # find the fundamental frequency\n",
    "    freq = find_fundamental(audio, SAMPLE_RATE)\n",
    "\n",
    "    # check if its close to our target\n",
    "    if abs(freq - TARGET_FREQ) < TOLERANCE:\n",
    "        print(f\"Detected {freq:.0f} Hz! (Target: {TARGET_FREQ} Hz)\")\n",
    "\n",
    "# Start listening\n",
    "print(f'Listening for ~{TARGET_FREQ} Hz...press Ctrl+C to stop')\n",
    "print(f'Try whistling or playing a tone :)')\n",
    "\n",
    "try:\n",
    "    with sd.InputStream(\n",
    "        samplerate=SAMPLE_RATE,\n",
    "        blocksize=BLOCK_SIZE,\n",
    "        channels=1,\n",
    "        callback=audio_callback\n",
    "    ):\n",
    "        sd.sleep(30000) # listen for 30 seconds\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Demo - Radio Rex example with Arduino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send signal to Arduino when pitch is detected\n",
    "\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# config\n",
    "SAMPLE_RATE = 44100\n",
    "BLOCK_SIZE = 4096\n",
    "TARGET_FREQ = 500 # frequency to detect - refer to Radio Rex example!\n",
    "TOLERANCE = 50\n",
    "MIN_VOLUME = 0.01\n",
    "\n",
    "SERIAL_PORT = '/dev/tty.usbmodem1101' # <--- Change this\n",
    "BAUD_RATE = 9600\n",
    "\n",
    "\n",
    "\n",
    "# connect to arduino\n",
    "try:\n",
    "    arduino = serial.Serial(SERIAL_PORT, BAUD_RATE)\n",
    "    time.sleep(2) # wait for arduino to reset\n",
    "    print(f\"Connected to Arduino on {SERIAL_PORT}\")\n",
    "except:\n",
    "    arduino = None\n",
    "    print(\"Could not connect to Arduino - running in test mode\")\n",
    "\n",
    "def find_fundamental(audio_data, sample_rate):\n",
    "    \"\"\"Find the fundamental frequency in audio data using FFT\"\"\"\n",
    "\n",
    "    # Compute FFT\n",
    "    fft = np.fft.fft(audio_data)\n",
    "    magnitude = np.abs(fft)\n",
    "\n",
    "    # get frequency bins\n",
    "    freq_bins = np.fft.fftfreq(len(audio_data), 1/sample_rate)\n",
    "\n",
    "    # only look at the positive frequencies betweeen 50-2000 Hz\n",
    "    valid_idx = (freq_bins > 50) & (freq_bins < 2000)\n",
    "\n",
    "    if not np.any(valid_idx):\n",
    "        return 0\n",
    "\n",
    "    valid_freq = freq_bins[valid_idx]\n",
    "    valid_magnitude = magnitude[valid_idx]\n",
    "\n",
    "    # find peak frequency\n",
    "    peak_idx = np.argmax(valid_magnitude)\n",
    "    return valid_freq[peak_idx]\n",
    "\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"Called for each audio block\"\"\"\n",
    "    if status:\n",
    "        print(f'Status: {status}')\n",
    "\n",
    "    # flatten to 1D array\n",
    "    audio = indata[:, 0]\n",
    "\n",
    "    # check if there is enough volume\n",
    "    volume = np.sqrt(np.mean(audio**2))\n",
    "    if volume < MIN_VOLUME:\n",
    "        return\n",
    "\n",
    "    # find the fundamental frequency\n",
    "    freq = find_fundamental(audio, SAMPLE_RATE)\n",
    "\n",
    "    # check if its close to our target\n",
    "    if abs(freq - TARGET_FREQ) < TOLERANCE:\n",
    "        print(f\"Detected {freq:.0f} Hz! (Target: {TARGET_FREQ} Hz)\") \n",
    "        # SEND TO ARDUINO TO DO SOMETHING COOL!\n",
    "        if arduino:\n",
    "            print(f\"sending 1 to Arduino\")\n",
    "            arduino.write(b'1') # send '1' to Arduino\n",
    "\n",
    "    # Start listening\n",
    "print(f'Listening for ~{TARGET_FREQ} Hz...press Ctrl+C to stop')\n",
    "print(f'Try whistling or playing a tone :)')\n",
    "print(f'When detected, Arduino LED will blink!')\n",
    "\n",
    "try:\n",
    "    with sd.InputStream(\n",
    "        samplerate=SAMPLE_RATE,\n",
    "        blocksize=BLOCK_SIZE,\n",
    "        channels=1,\n",
    "        callback=audio_callback\n",
    "    ):\n",
    "        sd.sleep(30000) # listen for 30 seconds\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped\")\n",
    "finally:\n",
    "    if arduino:\n",
    "        arduino.close()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arduino code - copy + paste and load onto Arduino\n",
    "\n",
    "f\"\"\"\n",
    "\n",
    "const int LED_PIN = 13; // built-in LED on most Arduinos\n",
    "\n",
    "void setup() {\n",
    "    Serial.begin(9600);\n",
    "    pinMode(LED_PIN, OUTPUT);\n",
    "    digitalWrite(LED_PIN, LOW);\n",
    "}\n",
    "\n",
    "void loop() {\n",
    "    // check if data received from Python\n",
    "    if (Serial.available() > 0) {\n",
    "        char received = Seria.read();\n",
    "\n",
    "        if (received == '1') {\n",
    "            // blink the LED\n",
    "            digitalWrite(LED_PIN, HIGH);\n",
    "            delay(200);\n",
    "            digitalWRite(LED_PIN, LOW);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Make something activate with pitch (simple)\n",
    "# Consider sending signal to a p5 sketch over OSC for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Make something activate with speech and have it activate something physical in the world (harder!) \n",
    "# Hint: Analyze a speech recording and determine a fundamental frequency / format in that speech utterance\n",
    "# For example, with Radio Rex, it was \"concluded that Rex was sensitive to vowels with resonances in the 500 Hz range\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Credit\n",
    "\n",
    "# Playing with playback speed, volume, other effects\n",
    "# Reconstructing sound with iFFT\n",
    "# Look at auto correleation\n",
    "# Pitch detection\n",
    "# Other kinds of time/frequency/amplitude functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
